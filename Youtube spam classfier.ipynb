{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00d12c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in d:\\java1\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in d:\\java1\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\java1\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\java1\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in d:\\java1\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in d:\\java1\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\java1\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\java1\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\java1\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in d:\\java1\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\java1\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in d:\\java1\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in d:\\java1\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.24.0)\n",
      "Requirement already satisfied: setuptools in d:\\java1\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\java1\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\java1\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in d:\\java1\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\java1\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\java1\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.57.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in d:\\java1\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in d:\\java1\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in d:\\java1\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\java1\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\java1\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\java1\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in d:\\java1\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\java1\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\java1\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\java1\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\java1\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\java1\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\java1\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\java1\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in d:\\java1\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\java1\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\java1\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\java1\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\java1\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\java1\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\java1\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\java1\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a984c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import datetime\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62dcbefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_writer(log_dir):\n",
    "    return tf.summary.create_file_writer(logdir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1deb849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_MODEL = hp.HParam('model', hp.Discrete(['Random Forest', 'SVM', 'Logistic Regression', 'SGD Classifier', 'Naive Bayes', 'K Nearest Neighbors', 'Decision Tree']))\n",
    "HP_TRAIN_SIZE = hp.HParam('train_size', hp.RealInterval(0.0, 1.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21c88b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "with tf.summary.create_file_writer(log_dir).as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_MODEL, HP_TRAIN_SIZE],\n",
    "        metrics=[hp.Metric('accuracy', display_name='Accuracy')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80192f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "Psy = pd.read_csv(\"C:/Users/goura/Downloads/archive (23)/Youtube01-Psy.csv\")\n",
    "Katy = pd.read_csv(\"C:/Users/goura/Downloads/archive (23)/Youtube02-KatyPerry.csv\")\n",
    "Eminem = pd.read_csv(\"C:/Users/goura/Downloads/archive (23)/Youtube04-Eminem.csv\")\n",
    "Shakira = pd.read_csv(\"C:/Users/goura/Downloads/archive (23)/Youtube05-Shakira.csv\")\n",
    "LMFAO = pd.read_csv(\"C:/Users/goura/Downloads/archive (23)/Youtube03-LMFAO.csv\")\n",
    "df = pd.concat([Shakira, Eminem, Katy, Psy, LMFAO])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eff2ddf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['COMMENT_ID', 'AUTHOR', 'DATE', 'CONTENT', 'CLASS'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b21b81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1956, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('DATE', axis=1, inplace=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9728da25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['COMMENT_ID', 'AUTHOR', 'CONTENT', 'CLASS'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91f00bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z13lgffb5w3ddx1ul22qy1wxspy5cpkz504</td>\n",
       "      <td>dharma pal</td>\n",
       "      <td>Nice song﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z123dbgb0mqjfxbtz22ucjc5jvzcv3ykj</td>\n",
       "      <td>Tiza Arellano</td>\n",
       "      <td>I love song ﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>z12quxxp2vutflkxv04cihggzt2azl34pms0k</td>\n",
       "      <td>Prìñçeśś Âliś Łøvê Dømíñø Mâđiś™ ﻿</td>\n",
       "      <td>I love song ﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z12icv3ysqvlwth2c23eddlykyqut5z1h</td>\n",
       "      <td>Eric Gonzalez</td>\n",
       "      <td>860,000,000 lets make it first female to reach...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z133stly3kete3tly22petvwdpmghrlli</td>\n",
       "      <td>Analena López</td>\n",
       "      <td>shakira is best for worldcup﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              COMMENT_ID                              AUTHOR  \\\n",
       "0    z13lgffb5w3ddx1ul22qy1wxspy5cpkz504                          dharma pal   \n",
       "1      z123dbgb0mqjfxbtz22ucjc5jvzcv3ykj                       Tiza Arellano   \n",
       "2  z12quxxp2vutflkxv04cihggzt2azl34pms0k  Prìñçeśś Âliś Łøvê Dømíñø Mâđiś™ ﻿   \n",
       "3      z12icv3ysqvlwth2c23eddlykyqut5z1h                       Eric Gonzalez   \n",
       "4      z133stly3kete3tly22petvwdpmghrlli                       Analena López   \n",
       "\n",
       "                                             CONTENT  CLASS  \n",
       "0                                         Nice song﻿      0  \n",
       "1                                      I love song ﻿      0  \n",
       "2                                      I love song ﻿      0  \n",
       "3  860,000,000 lets make it first female to reach...      0  \n",
       "4                      shakira is best for worldcup﻿      0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7a43847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAGYCAYAAACzlLNPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbuklEQVR4nO3dfWyV533/8Y+LwQWEXR6GjVW3oZLVpYNtqROxkGww8ZB2oSyKNLqRRZ3GOiJSOjcwGsS2kkg1DfsV0MrGmi4LNIzSf8YWqW0G2SZWRLISp3SF9UFTaWIWPNbNsyG1bErO748qRzIktGkN9oVfL+mWeu77e06uE/XEb10+x6emUqlUAgBQmDeN9AIAAH4SIgYAKJKIAQCKJGIAgCKJGACgSCIGACiSiAEAiiRiAIAi1Y70Aq6WV155JS+99FKmTJmSmpqakV4OAPBjqFQqOXfuXJqbm/OmN115r+W6jZiXXnopLS0tI70MAOAn0NXVlbe+9a1XnLluI2bKlClJfvgvob6+foRXAwD8OPr6+tLS0lL9OX4l123EvPorpPr6ehEDAIX5cd4K4o29AECRRAwAUCQRAwAUScQAAEUSMQBAkUQMAFAkEQMAFEnEAABFEjEAQJFEDABQJBEDABRJxAAARXrDEfMv//Ived/73pfm5ubU1NTk7/7u74Zcr1Qq2bx5c5qbmzNx4sQsXLgwJ0+eHDIzMDCQtWvXZsaMGZk8eXKWL1+e06dPD5np6enJvffem4aGhjQ0NOTee+/N//3f/73hJwgAXJ/ecMS8/PLL+YVf+IXs3LnzNa9v3bo127Zty86dO3Ps2LE0NTVlyZIlOXfuXHWmvb09Bw4cyP79+3PkyJGcP38+y5Yty8WLF6szK1euzPHjx/PUU0/lqaeeyvHjx3Pvvff+BE8RALge1VQqlcpPfOeamhw4cCB33XVXkh/uwjQ3N6e9vT0f/ehHk/xw16WxsTGPPPJIVq9end7e3vzMz/xMnnjiibz//e9Pkrz00ktpaWnJF7/4xdxxxx35xje+kXe961159tlnM2/evCTJs88+m1tvvTXf/OY38853vvNHrq2vry8NDQ3p7e1NfX39T/oUi3TDg18Y6SVwDX33E3eO9BIAhs0b+fk9rO+JOXXqVLq7u7N06dLqubq6uixYsCBHjx5NknR2dubChQtDZpqbmzNnzpzqzDPPPJOGhoZqwCTJL/3SL6WhoaE6c6mBgYH09fUNOQCA69ewRkx3d3eSpLGxccj5xsbG6rXu7u5MmDAhU6dOveLMzJkzL3v8mTNnVmcutWXLlur7ZxoaGtLS0vJTPx8AYPS6Kp9OqqmpGXK7Uqlcdu5Sl8681vyVHmfjxo3p7e2tHl1dXT/BygGAUgxrxDQ1NSXJZbslZ8+ere7ONDU1ZXBwMD09PVec+a//+q/LHv+///u/L9vleVVdXV3q6+uHHADA9WtYI2b27NlpamrKoUOHqucGBwdz+PDhzJ8/P0nS1taW8ePHD5k5c+ZMTpw4UZ259dZb09vbm6985SvVmX/9139Nb29vdQYAGNtq3+gdzp8/n//4j/+o3j516lSOHz+eadOm5W1ve1va29vT0dGR1tbWtLa2pqOjI5MmTcrKlSuTJA0NDVm1alXWrVuX6dOnZ9q0aVm/fn3mzp2bxYsXJ0luvPHGvOc978kHP/jBfPrTn06S/P7v/36WLVv2Y30yCQC4/r3hiHnuuefyq7/6q9XbDzzwQJLkAx/4QHbv3p0NGzakv78/a9asSU9PT+bNm5eDBw9mypQp1fts3749tbW1WbFiRfr7+7No0aLs3r0748aNq878zd/8TT784Q9XP8W0fPny1/3bNADA2PNT/Z2Y0czfiWGs8HdigOvJiP2dGACAa0XEAABFEjEAQJFEDABQJBEDABRJxAAARRIxAECRRAwAUCQRAwAUScQAAEV6w9+dBMDI8bUiY4uvFbkyOzEAQJFEDABQJBEDABRJxAAARRIxAECRRAwAUCQRAwAUScQAAEUSMQBAkUQMAFAkEQMAFEnEAABFEjEAQJFEDABQJBEDABRJxAAARRIxAECRRAwAUCQRAwAUScQAAEUSMQBAkUQMAFAkEQMAFEnEAABFEjEAQJFEDABQJBEDABRJxAAARRIxAECRRAwAUCQRAwAUScQAAEUSMQBAkUQMAFAkEQMAFEnEAABFEjEAQJFEDABQJBEDABRJxAAARRIxAECRRAwAUCQRAwAUScQAAEUSMQBAkUQMAFAkEQMAFEnEAABFGvaI+cEPfpA/+qM/yuzZszNx4sS84x3vyMMPP5xXXnmlOlOpVLJ58+Y0Nzdn4sSJWbhwYU6ePDnkcQYGBrJ27drMmDEjkydPzvLly3P69OnhXi4AUKhhj5hHHnkkf/mXf5mdO3fmG9/4RrZu3Zo//dM/zac+9anqzNatW7Nt27bs3Lkzx44dS1NTU5YsWZJz585VZ9rb23PgwIHs378/R44cyfnz57Ns2bJcvHhxuJcMABSodrgf8Jlnnsmv//qv584770yS3HDDDfnc5z6X5557LskPd2F27NiRTZs25e67706S7NmzJ42Njdm3b19Wr16d3t7ePPbYY3niiSeyePHiJMnevXvT0tKSp59+OnfcccdwLxsAKMyw78Tcfvvt+cd//Md8+9vfTpJ87Wtfy5EjR/Jrv/ZrSZJTp06lu7s7S5curd6nrq4uCxYsyNGjR5MknZ2duXDhwpCZ5ubmzJkzpzpzqYGBgfT19Q05AIDr17DvxHz0ox9Nb29vfvZnfzbjxo3LxYsX8/GPfzy/9Vu/lSTp7u5OkjQ2Ng65X2NjY1544YXqzIQJEzJ16tTLZl69/6W2bNmShx56aLifDgAwSg37TsznP//57N27N/v27cvzzz+fPXv25P/9v/+XPXv2DJmrqakZcrtSqVx27lJXmtm4cWN6e3urR1dX10/3RACAUW3Yd2L+8A//MA8++GB+8zd/M0kyd+7cvPDCC9myZUs+8IEPpKmpKckPd1tmzZpVvd/Zs2eruzNNTU0ZHBxMT0/PkN2Ys2fPZv78+a/5z62rq0tdXd1wPx0AYJQa9p2Y73//+3nTm4Y+7Lhx46ofsZ49e3aamppy6NCh6vXBwcEcPny4GihtbW0ZP378kJkzZ87kxIkTrxsxAMDYMuw7Me973/vy8Y9/PG9729vycz/3c/nqV7+abdu25Xd/93eT/PDXSO3t7eno6Ehra2taW1vT0dGRSZMmZeXKlUmShoaGrFq1KuvWrcv06dMzbdq0rF+/PnPnzq1+WgkAGNuGPWI+9alP5Y//+I+zZs2anD17Ns3NzVm9enX+5E/+pDqzYcOG9Pf3Z82aNenp6cm8efNy8ODBTJkypTqzffv21NbWZsWKFenv78+iRYuye/fujBs3briXDAAUqKZSqVRGehFXQ19fXxoaGtLb25v6+vqRXs41dcODXxjpJXANffcTd470EriGvL7HlrH4+n4jP799dxIAUCQRAwAUScQAAEUSMQBAkUQMAFAkEQMAFEnEAABFEjEAQJFEDABQJBEDABRJxAAARRIxAECRRAwAUCQRAwAUScQAAEUSMQBAkUQMAFAkEQMAFEnEAABFEjEAQJFEDABQJBEDABRJxAAARRIxAECRRAwAUCQRAwAUScQAAEUSMQBAkUQMAFAkEQMAFEnEAABFEjEAQJFEDABQJBEDABRJxAAARRIxAECRRAwAUCQRAwAUScQAAEUSMQBAkUQMAFAkEQMAFEnEAABFEjEAQJFEDABQJBEDABRJxAAARRIxAECRRAwAUCQRAwAUScQAAEUSMQBAkUQMAFAkEQMAFEnEAABFEjEAQJFEDABQJBEDABRJxAAARboqEfOf//mf+e3f/u1Mnz49kyZNyi/+4i+ms7Ozer1SqWTz5s1pbm7OxIkTs3Dhwpw8eXLIYwwMDGTt2rWZMWNGJk+enOXLl+f06dNXY7kAQIGGPWJ6enpy2223Zfz48fnSl76Uf//3f88nP/nJvOUtb6nObN26Ndu2bcvOnTtz7NixNDU1ZcmSJTl37lx1pr29PQcOHMj+/ftz5MiRnD9/PsuWLcvFixeHe8kAQIFqh/sBH3nkkbS0tOTxxx+vnrvhhhuq/7tSqWTHjh3ZtGlT7r777iTJnj170tjYmH379mX16tXp7e3NY489lieeeCKLFy9OkuzduzctLS15+umnc8cddwz3sgGAwgz7TsyTTz6Zm2++Ob/xG7+RmTNn5qabbspnPvOZ6vVTp06lu7s7S5curZ6rq6vLggULcvTo0SRJZ2dnLly4MGSmubk5c+bMqc5camBgIH19fUMOAOD6NewR853vfCe7du1Ka2tr/uEf/iH33XdfPvzhD+ezn/1skqS7uztJ0tjYOOR+jY2N1Wvd3d2ZMGFCpk6d+rozl9qyZUsaGhqqR0tLy3A/NQBgFBn2iHnllVfy7ne/Ox0dHbnpppuyevXqfPCDH8yuXbuGzNXU1Ay5XalULjt3qSvNbNy4Mb29vdWjq6vrp3siAMCoNuwRM2vWrLzrXe8acu7GG2/Miy++mCRpampKkst2VM6ePVvdnWlqasrg4GB6enped+ZSdXV1qa+vH3IAANevYY+Y2267Ld/61reGnPv2t7+dt7/97UmS2bNnp6mpKYcOHapeHxwczOHDhzN//vwkSVtbW8aPHz9k5syZMzlx4kR1BgAY24b900kf+chHMn/+/HR0dGTFihX5yle+kkcffTSPPvpokh/+Gqm9vT0dHR1pbW1Na2trOjo6MmnSpKxcuTJJ0tDQkFWrVmXdunWZPn16pk2blvXr12fu3LnVTysBAGPbsEfMLbfckgMHDmTjxo15+OGHM3v27OzYsSP33HNPdWbDhg3p7+/PmjVr0tPTk3nz5uXgwYOZMmVKdWb79u2pra3NihUr0t/fn0WLFmX37t0ZN27ccC8ZAChQTaVSqYz0Iq6Gvr6+NDQ0pLe3d8y9P+aGB78w0kvgGvruJ+4c6SVwDXl9jy1j8fX9Rn5+++4kAKBIIgYAKJKIAQCKJGIAgCKJGACgSCIGACiSiAEAiiRiAIAiiRgAoEgiBgAokogBAIokYgCAIokYAKBIIgYAKJKIAQCKJGIAgCKJGACgSCIGACiSiAEAiiRiAIAiiRgAoEgiBgAokogBAIokYgCAIokYAKBIIgYAKJKIAQCKJGIAgCKJGACgSCIGACiSiAEAiiRiAIAiiRgAoEgiBgAokogBAIokYgCAIokYAKBIIgYAKJKIAQCKJGIAgCKJGACgSCIGACiSiAEAiiRiAIAiiRgAoEgiBgAokogBAIokYgCAIokYAKBIIgYAKJKIAQCKJGIAgCKJGACgSCIGACiSiAEAiiRiAIAiiRgAoEgiBgAokogBAIp01SNmy5YtqampSXt7e/VcpVLJ5s2b09zcnIkTJ2bhwoU5efLkkPsNDAxk7dq1mTFjRiZPnpzly5fn9OnTV3u5AEAhrmrEHDt2LI8++mh+/ud/fsj5rVu3Ztu2bdm5c2eOHTuWpqamLFmyJOfOnavOtLe358CBA9m/f3+OHDmS8+fPZ9myZbl48eLVXDIAUIirFjHnz5/PPffck8985jOZOnVq9XylUsmOHTuyadOm3H333ZkzZ0727NmT73//+9m3b1+SpLe3N4899lg++clPZvHixbnpppuyd+/efP3rX8/TTz99tZYMABTkqkXM/fffnzvvvDOLFy8ecv7UqVPp7u7O0qVLq+fq6uqyYMGCHD16NEnS2dmZCxcuDJlpbm7OnDlzqjOXGhgYSF9f35ADALh+1V6NB92/f3+ef/75HDt27LJr3d3dSZLGxsYh5xsbG/PCCy9UZyZMmDBkB+fVmVfvf6ktW7bkoYceGo7lAwAFGPadmK6urvzBH/xB9u7dmze/+c2vO1dTUzPkdqVSuezcpa40s3HjxvT29laPrq6uN754AKAYwx4xnZ2dOXv2bNra2lJbW5va2tocPnw4f/Znf5ba2trqDsylOypnz56tXmtqasrg4GB6enped+ZSdXV1qa+vH3IAANevYY+YRYsW5etf/3qOHz9ePW6++ebcc889OX78eN7xjnekqakphw4dqt5ncHAwhw8fzvz585MkbW1tGT9+/JCZM2fO5MSJE9UZAGBsG/b3xEyZMiVz5swZcm7y5MmZPn169Xx7e3s6OjrS2tqa1tbWdHR0ZNKkSVm5cmWSpKGhIatWrcq6desyffr0TJs2LevXr8/cuXMve6MwADA2XZU39v4oGzZsSH9/f9asWZOenp7MmzcvBw8ezJQpU6oz27dvT21tbVasWJH+/v4sWrQou3fvzrhx40ZiyQDAKFNTqVQqI72Iq6Gvry8NDQ3p7e0dc++PueHBL4z0EriGvvuJO0d6CVxDXt9jy1h8fb+Rn9++OwkAKJKIAQCKJGIAgCKJGACgSCIGACiSiAEAiiRiAIAiiRgAoEgiBgAokogBAIokYgCAIokYAKBIIgYAKJKIAQCKJGIAgCKJGACgSCIGACiSiAEAiiRiAIAiiRgAoEgiBgAokogBAIokYgCAIokYAKBIIgYAKJKIAQCKJGIAgCKJGACgSCIGACiSiAEAiiRiAIAiiRgAoEgiBgAokogBAIokYgCAIokYAKBIIgYAKJKIAQCKJGIAgCKJGACgSCIGACiSiAEAiiRiAIAiiRgAoEgiBgAokogBAIokYgCAIokYAKBIIgYAKJKIAQCKJGIAgCKJGACgSCIGACiSiAEAiiRiAIAiiRgAoEgiBgAokogBAIokYgCAIg17xGzZsiW33HJLpkyZkpkzZ+auu+7Kt771rSEzlUolmzdvTnNzcyZOnJiFCxfm5MmTQ2YGBgaydu3azJgxI5MnT87y5ctz+vTp4V4uAFCoYY+Yw4cP5/7778+zzz6bQ4cO5Qc/+EGWLl2al19+uTqzdevWbNu2LTt37syxY8fS1NSUJUuW5Ny5c9WZ9vb2HDhwIPv378+RI0dy/vz5LFu2LBcvXhzuJQMABaod7gd86qmnhtx+/PHHM3PmzHR2duZXfuVXUqlUsmPHjmzatCl33313kmTPnj1pbGzMvn37snr16vT29uaxxx7LE088kcWLFydJ9u7dm5aWljz99NO54447hnvZAEBhrvp7Ynp7e5Mk06ZNS5KcOnUq3d3dWbp0aXWmrq4uCxYsyNGjR5MknZ2duXDhwpCZ5ubmzJkzpzpzqYGBgfT19Q05AIDr11WNmEqlkgceeCC333575syZkyTp7u5OkjQ2Ng6ZbWxsrF7r7u7OhAkTMnXq1NedudSWLVvS0NBQPVpaWob76QAAo8hVjZgPfehD+bd/+7d87nOfu+xaTU3NkNuVSuWyc5e60szGjRvT29tbPbq6un7yhQMAo95Vi5i1a9fmySefzD//8z/nrW99a/V8U1NTkly2o3L27Nnq7kxTU1MGBwfT09PzujOXqqurS319/ZADALh+DXvEVCqVfOhDH8rf/u3f5p/+6Z8ye/bsIddnz56dpqamHDp0qHpucHAwhw8fzvz585MkbW1tGT9+/JCZM2fO5MSJE9UZAGBsG/ZPJ91///3Zt29f/v7v/z5Tpkyp7rg0NDRk4sSJqampSXt7ezo6OtLa2prW1tZ0dHRk0qRJWblyZXV21apVWbduXaZPn55p06Zl/fr1mTt3bvXTSgDA2DbsEbNr164kycKFC4ecf/zxx/M7v/M7SZINGzakv78/a9asSU9PT+bNm5eDBw9mypQp1fnt27entrY2K1asSH9/fxYtWpTdu3dn3Lhxw71kAKBANZVKpTLSi7ga+vr60tDQkN7e3jH3/pgbHvzCSC+Ba+i7n7hzpJfANeT1PbaMxdf3G/n57buTAIAiiRgAoEgiBgAokogBAIokYgCAIokYAKBIIgYAKJKIAQCKJGIAgCKJGACgSCIGACiSiAEAiiRiAIAiiRgAoEgiBgAokogBAIokYgCAIokYAKBIIgYAKJKIAQCKJGIAgCKJGACgSCIGACiSiAEAiiRiAIAiiRgAoEgiBgAokogBAIokYgCAIokYAKBIIgYAKJKIAQCKJGIAgCKJGACgSCIGACiSiAEAiiRiAIAiiRgAoEgiBgAokogBAIokYgCAIokYAKBIIgYAKJKIAQCKJGIAgCKJGACgSCIGACiSiAEAiiRiAIAiiRgAoEgiBgAokogBAIokYgCAIokYAKBIIgYAKJKIAQCKJGIAgCKJGACgSCIGACjSqI+Yv/iLv8js2bPz5je/OW1tbfnyl7880ksCAEaBUR0xn//859Pe3p5Nmzblq1/9an75l385733ve/Piiy+O9NIAgBE2qiNm27ZtWbVqVX7v934vN954Y3bs2JGWlpbs2rVrpJcGAIyw2pFewOsZHBxMZ2dnHnzwwSHnly5dmqNHj142PzAwkIGBgert3t7eJElfX9/VXego9MrA90d6CVxDY/H/42OZ1/fYMhZf368+50ql8iNnR23EfO9738vFixfT2Ng45HxjY2O6u7svm9+yZUseeuihy863tLRctTXCaNCwY6RXAFwtY/n1fe7cuTQ0NFxxZtRGzKtqamqG3K5UKpedS5KNGzfmgQceqN5+5ZVX8r//+7+ZPn36a85zfenr60tLS0u6urpSX18/0ssBhpHX99hSqVRy7ty5NDc3/8jZURsxM2bMyLhx4y7bdTl79uxluzNJUldXl7q6uiHn3vKWt1zNJTIK1dfX+48cXKe8vseOH7UD86pR+8beCRMmpK2tLYcOHRpy/tChQ5k/f/4IrQoAGC1G7U5MkjzwwAO59957c/PNN+fWW2/No48+mhdffDH33XffSC8NABhhozpi3v/+9+d//ud/8vDDD+fMmTOZM2dOvvjFL+btb3/7SC+NUaauri4f+9jHLvuVIlA+r29eT03lx/kMEwDAKDNq3xMDAHAlIgYAKJKIAQCKJGIAgCKJGACgSKP6I9YAjD2nT5/Orl27cvTo0XR3d6empiaNjY2ZP39+7rvvPt+JR5WPWHNd6urqysc+9rH89V//9UgvBXgDjhw5kve+971paWnJ0qVL09jYmEqlkrNnz+bQoUPp6urKl770pdx2220jvVRGARHDdelrX/ta3v3ud+fixYsjvRTgDbjlllty++23Z/v27a95/SMf+UiOHDmSY8eOXeOVMRqJGIr05JNPXvH6d77znaxbt07EQGEmTpyY48eP553vfOdrXv/mN7+Zm266Kf39/dd4ZYxG3hNDke66667U1NTkSg1eU1NzDVcEDIdZs2bl6NGjrxsxzzzzTGbNmnWNV8VoJWIo0qxZs/Lnf/7nueuuu17z+vHjx9PW1nZtFwX81NavX5/77rsvnZ2dWbJkSRobG1NTU5Pu7u4cOnQof/VXf5UdO3aM9DIZJUQMRWpra8vzzz//uhHzo3ZpgNFpzZo1mT59erZv355Pf/rT1V8Jjxs3Lm1tbfnsZz+bFStWjPAqGS28J4YiffnLX87LL7+c97znPa95/eWXX85zzz2XBQsWXOOVAcPlwoUL+d73vpckmTFjRsaPHz/CK2K0ETEAQJH8xV4AoEgiBgAokogBAIokYgCAIokYAKBIIgYAKJKIAQCKJGIAgCL9f2kEVROa0lT8AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['CLASS'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0487036c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1005\n",
      "0     951\n",
      "Name: CLASS, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "classes = df['CLASS']\n",
    "print(classes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31bbf555",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_messages = df[\"CONTENT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18bbf7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\goura\\AppData\\Local\\Temp\\ipykernel_19840\\3240830285.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = df['CONTENT'].str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$', 'emailaddress')\n",
      "C:\\Users\\goura\\AppData\\Local\\Temp\\ipykernel_19840\\3240830285.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$', 'webaddress')\n",
      "C:\\Users\\goura\\AppData\\Local\\Temp\\ipykernel_19840\\3240830285.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = processed.str.replace(r'£|\\$', 'moneysymb')\n",
      "C:\\Users\\goura\\AppData\\Local\\Temp\\ipykernel_19840\\3240830285.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$', 'phonenumbr')\n",
      "C:\\Users\\goura\\AppData\\Local\\Temp\\ipykernel_19840\\3240830285.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n",
      "C:\\Users\\goura\\AppData\\Local\\Temp\\ipykernel_19840\\3240830285.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
      "C:\\Users\\goura\\AppData\\Local\\Temp\\ipykernel_19840\\3240830285.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = processed.str.replace(r'\\s+', ' ')\n",
      "C:\\Users\\goura\\AppData\\Local\\Temp\\ipykernel_19840\\3240830285.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "# Replace email addresses, URLs, phone numbers, other numbers, symbols, and remove stop words\n",
    "processed = df['CONTENT'].str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$', 'emailaddress')\n",
    "processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$', 'webaddress')\n",
    "processed = processed.str.replace(r'£|\\$', 'moneysymb')\n",
    "processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$', 'phonenumbr')\n",
    "processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n",
    "processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "processed = processed.str.replace(r'\\s+', ' ')\n",
    "processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n",
    "processed = processed.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d288853f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                           Nice song﻿\n",
      "1                                        I love song ﻿\n",
      "2                                        I love song ﻿\n",
      "3    860,000,000 lets make it first female to reach...\n",
      "4                        shakira is best for worldcup﻿\n",
      "5                    The best world cup song ever!!!!﻿\n",
      "6                                              I love﻿\n",
      "7    SEE SOME MORE SONG OPEN GOOGLE AND TYPE Shakir...\n",
      "8                                            Awesome ﻿\n",
      "9                                    I like shakira..﻿\n",
      "Name: CONTENT, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(text_messages[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e16dcd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\goura\\AppData\\Local\\Temp\\ipykernel_19840\\2241229190.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
      "C:\\Users\\goura\\AppData\\Local\\Temp\\ipykernel_19840\\2241229190.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = processed.str.replace(r'\\s+', ' ')\n",
      "C:\\Users\\goura\\AppData\\Local\\Temp\\ipykernel_19840\\2241229190.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n"
     ]
    }
   ],
   "source": [
    "processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "\n",
    "# Replace whitespace between terms with a single space\n",
    "processed = processed.str.replace(r'\\s+', ' ')\n",
    "\n",
    "# Remove leading and trailing whitespace\n",
    "processed = processed.str.replace(r'^\\s+|\\s+?$', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "603762ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                           Nice song﻿\n",
      "1                                        I love song ﻿\n",
      "2                                        I love song ﻿\n",
      "3    860,000,000 lets make it first female to reach...\n",
      "4                        shakira is best for worldcup﻿\n",
      "5                    The best world cup song ever!!!!﻿\n",
      "6                                              I love﻿\n",
      "7    SEE SOME MORE SONG OPEN GOOGLE AND TYPE Shakir...\n",
      "8                                            Awesome ﻿\n",
      "9                                    I like shakira..﻿\n",
      "Name: CONTENT, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(text_messages[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d068256c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                              nice song\n",
      "1                                            i love song\n",
      "2                                            i love song\n",
      "3      numbr numbr numbr lets make it first female to...\n",
      "4                           shakira is best for worldcup\n",
      "                             ...                        \n",
      "433                      like this comment for no reason\n",
      "434                                       love this song\n",
      "435    this song is awesome these guys are the best l...\n",
      "436          how many thumbs up for louis saving the day\n",
      "437                                           nice numbr\n",
      "Name: CONTENT, Length: 1956, dtype: object\n"
     ]
    }
   ],
   "source": [
    "processed = processed.str.lower()\n",
    "print(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73f877bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "processed = processed.apply(lambda x: ' '.join(term for term in x.split() if term not in stop_words))\n",
    "\n",
    "# Stemming\n",
    "nltk.download('punkt')\n",
    "ps = nltk.PorterStemmer()\n",
    "processed = processed.apply(lambda x: ' '.join(ps.stem(term) for term in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3462a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              COMMENT_ID                              AUTHOR  \\\n",
      "0    z13lgffb5w3ddx1ul22qy1wxspy5cpkz504                          dharma pal   \n",
      "1      z123dbgb0mqjfxbtz22ucjc5jvzcv3ykj                       Tiza Arellano   \n",
      "2  z12quxxp2vutflkxv04cihggzt2azl34pms0k  Prìñçeśś Âliś Łøvê Dømíñø Mâđiś™ ﻿   \n",
      "3      z12icv3ysqvlwth2c23eddlykyqut5z1h                       Eric Gonzalez   \n",
      "4      z133stly3kete3tly22petvwdpmghrlli                       Analena López   \n",
      "\n",
      "                                             CONTENT  CLASS  \\\n",
      "0                                         Nice song﻿      0   \n",
      "1                                      I love song ﻿      0   \n",
      "2                                      I love song ﻿      0   \n",
      "3  860,000,000 lets make it first female to reach...      0   \n",
      "4                      shakira is best for worldcup﻿      0   \n",
      "\n",
      "                                   Processed_Content  \n",
      "0                                          nice song  \n",
      "1                                          love song  \n",
      "2                                          love song  \n",
      "3  numbr numbr numbr let make first femal reach o...  \n",
      "4                              shakira best worldcup  \n"
     ]
    }
   ],
   "source": [
    "# Preparing the final dataset\n",
    "df['Processed_Content'] = processed\n",
    "classes = df['CLASS']\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c174283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Create a bag-of-words model\n",
    "all_words = []\n",
    "for message in processed:\n",
    "    words = word_tokenize(message)\n",
    "    for w in words:\n",
    "        all_words.append(w)\n",
    "        \n",
    "all_words = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25783e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the most common words as features\n",
    "word_features = list(all_words.keys())[:1500]\n",
    "\n",
    "def find_features(message):\n",
    "    words = word_tokenize(message)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[word] = (word in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "# Applying the find_features function to each SMS message\n",
    "featuresets = [(find_features(text), label) for (text, label) in zip(df['Processed_Content'], classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bcfb0620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing datasets\n",
    "seed = 1\n",
    "np.random.seed = seed\n",
    "np.random.shuffle(featuresets)\n",
    "\n",
    "training, testing = model_selection.train_test_split(featuresets, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22825548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 3472\n",
      "Most common words: [('numbr', 1133), ('check', 581), ('video', 386), ('song', 340), ('com', 284), ('subscrib', 277), ('like', 272), ('youtub', 272), ('br', 258), ('pleas', 249), ('http', 236), ('love', 220), ('channel', 200), ('music', 157), ('make', 139)]\n"
     ]
    }
   ],
   "source": [
    "# print the total number of words and the 15 most common words\n",
    "print('Number of words: {}'.format(len(all_words)))\n",
    "print('Most common words: {}'.format(all_words.most_common(15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e92ee662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Obtaining dependency information for xgboost from https://files.pythonhosted.org/packages/24/ec/ad387100fa3cc2b9b81af0829b5ecfe75ec5bb19dd7c19d4fea06fb81802/xgboost-2.0.3-py3-none-win_amd64.whl.metadata\n",
      "  Downloading xgboost-2.0.3-py3-none-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in d:\\java1\\lib\\site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in d:\\java1\\lib\\site-packages (from xgboost) (1.10.1)\n",
      "Downloading xgboost-2.0.3-py3-none-win_amd64.whl (99.8 MB)\n",
      "   ---------------------------------------- 0.0/99.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/99.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/99.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/99.8 MB 819.2 kB/s eta 0:02:02\n",
      "   ---------------------------------------- 0.2/99.8 MB 1.1 MB/s eta 0:01:33\n",
      "   ---------------------------------------- 0.3/99.8 MB 1.4 MB/s eta 0:01:11\n",
      "   ---------------------------------------- 0.6/99.8 MB 2.2 MB/s eta 0:00:47\n",
      "   ---------------------------------------- 0.8/99.8 MB 2.5 MB/s eta 0:00:40\n",
      "   ---------------------------------------- 0.8/99.8 MB 2.5 MB/s eta 0:00:40\n",
      "   ---------------------------------------- 0.8/99.8 MB 2.5 MB/s eta 0:00:40\n",
      "   ---------------------------------------- 0.8/99.8 MB 2.5 MB/s eta 0:00:40\n",
      "   ---------------------------------------- 0.8/99.8 MB 2.5 MB/s eta 0:00:40\n",
      "   ---------------------------------------- 0.8/99.8 MB 2.5 MB/s eta 0:00:40\n",
      "   ---------------------------------------- 0.8/99.8 MB 2.5 MB/s eta 0:00:40\n",
      "   ---------------------------------------- 0.8/99.8 MB 2.5 MB/s eta 0:00:40\n",
      "   ---------------------------------------- 0.9/99.8 MB 1.3 MB/s eta 0:01:20\n",
      "   ---------------------------------------- 1.0/99.8 MB 1.4 MB/s eta 0:01:13\n",
      "   ---------------------------------------- 1.0/99.8 MB 1.4 MB/s eta 0:01:13\n",
      "   ---------------------------------------- 1.0/99.8 MB 1.4 MB/s eta 0:01:13\n",
      "   ---------------------------------------- 1.0/99.8 MB 1.4 MB/s eta 0:01:13\n",
      "   ---------------------------------------- 1.0/99.8 MB 1.4 MB/s eta 0:01:13\n",
      "   ---------------------------------------- 1.0/99.8 MB 1.4 MB/s eta 0:01:13\n",
      "   ---------------------------------------- 1.1/99.8 MB 1.1 MB/s eta 0:01:34\n",
      "   ---------------------------------------- 1.1/99.8 MB 1.0 MB/s eta 0:01:39\n",
      "   ---------------------------------------- 1.1/99.8 MB 992.1 kB/s eta 0:01:40\n",
      "   ---------------------------------------- 1.2/99.8 MB 991.3 kB/s eta 0:01:40\n",
      "   ---------------------------------------- 1.2/99.8 MB 991.3 kB/s eta 0:01:40\n",
      "    --------------------------------------- 1.9/99.8 MB 1.4 MB/s eta 0:01:08\n",
      "    --------------------------------------- 2.3/99.8 MB 1.8 MB/s eta 0:00:56\n",
      "   - -------------------------------------- 2.7/99.8 MB 2.0 MB/s eta 0:00:50\n",
      "   - -------------------------------------- 3.1/99.8 MB 2.2 MB/s eta 0:00:45\n",
      "   - -------------------------------------- 3.4/99.8 MB 2.3 MB/s eta 0:00:42\n",
      "   - -------------------------------------- 3.7/99.8 MB 2.5 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 4.1/99.8 MB 2.6 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 4.4/99.8 MB 2.7 MB/s eta 0:00:36\n",
      "   - -------------------------------------- 4.7/99.8 MB 2.8 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 5.1/99.8 MB 3.0 MB/s eta 0:00:32\n",
      "   -- ------------------------------------- 5.5/99.8 MB 3.1 MB/s eta 0:00:31\n",
      "   -- ------------------------------------- 5.8/99.8 MB 3.2 MB/s eta 0:00:29\n",
      "   -- ------------------------------------- 5.9/99.8 MB 3.3 MB/s eta 0:00:29\n",
      "   -- ------------------------------------- 5.9/99.8 MB 3.3 MB/s eta 0:00:29\n",
      "   -- ------------------------------------- 5.9/99.8 MB 3.3 MB/s eta 0:00:29\n",
      "   -- ------------------------------------- 7.1/99.8 MB 3.6 MB/s eta 0:00:26\n",
      "   -- ------------------------------------- 7.3/99.8 MB 3.6 MB/s eta 0:00:26\n",
      "   --- ------------------------------------ 7.8/99.8 MB 3.7 MB/s eta 0:00:25\n",
      "   --- ------------------------------------ 8.1/99.8 MB 3.8 MB/s eta 0:00:25\n",
      "   --- ------------------------------------ 8.6/99.8 MB 3.9 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 8.7/99.8 MB 3.9 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 9.3/99.8 MB 4.1 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 9.7/99.8 MB 4.1 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 9.9/99.8 MB 4.2 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 10.4/99.8 MB 4.5 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 10.8/99.8 MB 4.6 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 11.2/99.8 MB 5.7 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 11.5/99.8 MB 7.7 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 11.7/99.8 MB 7.4 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 12.3/99.8 MB 7.6 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 12.7/99.8 MB 7.4 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 13.0/99.8 MB 7.5 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 13.5/99.8 MB 7.5 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 13.5/99.8 MB 7.6 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 14.0/99.8 MB 7.6 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 14.2/99.8 MB 7.4 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 14.6/99.8 MB 7.5 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 14.9/99.8 MB 7.4 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 15.3/99.8 MB 7.3 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 15.6/99.8 MB 7.4 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 15.7/99.8 MB 7.1 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 16.0/99.8 MB 7.0 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 16.4/99.8 MB 7.9 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 16.6/99.8 MB 7.7 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 17.3/99.8 MB 7.4 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 17.8/99.8 MB 7.5 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 18.3/99.8 MB 7.6 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 18.8/99.8 MB 7.8 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 19.3/99.8 MB 7.8 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 19.9/99.8 MB 8.1 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 20.4/99.8 MB 8.1 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 20.9/99.8 MB 8.3 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 21.5/99.8 MB 8.3 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 21.9/99.8 MB 8.7 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 22.5/99.8 MB 8.6 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 22.5/99.8 MB 8.6 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 23.6/99.8 MB 9.0 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 24.1/99.8 MB 9.1 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 24.6/99.8 MB 9.8 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 25.1/99.8 MB 9.8 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 25.5/99.8 MB 9.8 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 26.0/99.8 MB 10.6 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 26.5/99.8 MB 10.7 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 26.9/99.8 MB 10.9 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 27.4/99.8 MB 10.6 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 27.8/99.8 MB 10.4 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 28.3/99.8 MB 10.4 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 28.8/99.8 MB 10.4 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 29.2/99.8 MB 10.4 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 29.5/99.8 MB 10.4 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 29.5/99.8 MB 10.4 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 29.5/99.8 MB 10.4 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 30.0/99.8 MB 9.5 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 31.5/99.8 MB 10.1 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 32.0/99.8 MB 10.1 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 32.4/99.8 MB 10.1 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 32.9/99.8 MB 10.4 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 33.4/99.8 MB 9.9 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 33.4/99.8 MB 9.9 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 33.4/99.8 MB 9.9 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 34.5/99.8 MB 9.2 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 34.7/99.8 MB 8.8 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 35.2/99.8 MB 9.0 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 35.3/99.8 MB 8.5 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 35.3/99.8 MB 8.5 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 35.3/99.8 MB 8.5 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 35.3/99.8 MB 8.5 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 37.0/99.8 MB 8.6 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 37.9/99.8 MB 8.7 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 39.0/99.8 MB 9.6 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 39.0/99.8 MB 9.6 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 39.4/99.8 MB 9.0 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 40.8/99.8 MB 10.4 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 40.8/99.8 MB 10.4 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 40.8/99.8 MB 10.4 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 42.3/99.8 MB 9.6 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 42.4/99.8 MB 9.8 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 42.4/99.8 MB 9.8 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 43.6/99.8 MB 9.5 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 44.2/99.8 MB 10.9 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 44.6/99.8 MB 10.4 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 44.7/99.8 MB 10.4 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 45.1/99.8 MB 10.2 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 46.0/99.8 MB 12.8 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 46.5/99.8 MB 12.4 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 47.0/99.8 MB 11.7 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 47.4/99.8 MB 11.5 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 47.7/99.8 MB 11.1 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 48.0/99.8 MB 10.7 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 48.5/99.8 MB 10.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 49.0/99.8 MB 9.8 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 49.5/99.8 MB 10.4 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 49.8/99.8 MB 10.9 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 50.0/99.8 MB 10.4 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 51.0/99.8 MB 9.6 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 51.4/99.8 MB 10.4 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 51.9/99.8 MB 10.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 52.3/99.8 MB 9.6 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 52.9/99.8 MB 10.6 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 53.2/99.8 MB 10.2 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 53.2/99.8 MB 10.2 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 53.9/99.8 MB 9.4 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 54.4/99.8 MB 9.4 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 55.1/99.8 MB 10.2 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 55.7/99.8 MB 9.9 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 56.2/99.8 MB 9.6 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 56.7/99.8 MB 9.8 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 56.7/99.8 MB 9.6 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 56.7/99.8 MB 9.6 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 56.7/99.8 MB 8.5 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 58.1/99.8 MB 9.9 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 58.1/99.8 MB 9.9 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 59.5/99.8 MB 9.9 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 59.5/99.8 MB 9.5 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 60.0/99.8 MB 9.5 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 60.5/99.8 MB 9.8 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 61.1/99.8 MB 9.8 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 61.7/99.8 MB 10.2 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 62.1/99.8 MB 9.9 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 62.7/99.8 MB 9.9 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 63.2/99.8 MB 9.8 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 63.6/99.8 MB 10.7 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 63.7/99.8 MB 10.2 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 64.6/99.8 MB 10.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 65.1/99.8 MB 10.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 65.2/99.8 MB 10.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 65.2/99.8 MB 10.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 66.2/99.8 MB 9.6 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 66.9/99.8 MB 9.8 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 67.0/99.8 MB 11.3 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 67.0/99.8 MB 11.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 67.6/99.8 MB 9.9 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 68.7/99.8 MB 10.6 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 68.9/99.8 MB 10.1 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 68.9/99.8 MB 10.1 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 68.9/99.8 MB 10.1 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 68.9/99.8 MB 10.1 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 68.9/99.8 MB 8.4 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 69.7/99.8 MB 8.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 70.4/99.8 MB 8.8 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 71.0/99.8 MB 8.7 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 71.1/99.8 MB 8.8 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 71.9/99.8 MB 8.7 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 71.9/99.8 MB 8.7 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 71.9/99.8 MB 8.7 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 73.6/99.8 MB 8.7 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 73.6/99.8 MB 8.7 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 73.6/99.8 MB 8.7 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 74.2/99.8 MB 8.5 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 74.2/99.8 MB 8.5 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 74.5/99.8 MB 7.9 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 75.7/99.8 MB 8.8 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 76.4/99.8 MB 8.6 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 76.7/99.8 MB 8.4 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 77.2/99.8 MB 8.4 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 78.1/99.8 MB 9.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 78.7/99.8 MB 8.8 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 79.2/99.8 MB 10.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 79.8/99.8 MB 10.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 80.4/99.8 MB 10.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 80.9/99.8 MB 10.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 81.5/99.8 MB 11.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 82.0/99.8 MB 10.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 82.5/99.8 MB 11.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 83.0/99.8 MB 10.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 83.5/99.8 MB 10.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 83.9/99.8 MB 11.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 84.2/99.8 MB 11.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 84.5/99.8 MB 11.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 85.2/99.8 MB 11.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 85.3/99.8 MB 10.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 85.3/99.8 MB 10.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 85.4/99.8 MB 10.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 85.4/99.8 MB 10.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 85.4/99.8 MB 9.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 85.4/99.8 MB 8.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 86.0/99.8 MB 8.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 86.5/99.8 MB 8.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 86.9/99.8 MB 8.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 86.9/99.8 MB 8.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 88.0/99.8 MB 8.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 88.5/99.8 MB 8.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 89.0/99.8 MB 8.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 89.6/99.8 MB 8.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 90.0/99.8 MB 8.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 90.4/99.8 MB 8.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 90.6/99.8 MB 8.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 90.7/99.8 MB 8.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 90.7/99.8 MB 8.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 90.7/99.8 MB 8.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 90.7/99.8 MB 8.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 90.7/99.8 MB 8.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 90.7/99.8 MB 8.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 90.7/99.8 MB 8.0 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 92.5/99.8 MB 6.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 93.3/99.8 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 93.3/99.8 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 93.4/99.8 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 93.4/99.8 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 93.4/99.8 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 93.4/99.8 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 93.4/99.8 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 93.4/99.8 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 93.4/99.8 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 93.4/99.8 MB 6.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 96.5/99.8 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  97.8/99.8 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  98.6/99.8 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.1/99.8 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 99.8/99.8 MB 6.6 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "94ff5bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbmNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Obtaining dependency information for lightgbm from https://files.pythonhosted.org/packages/e1/4c/4685ccfae9806f561de716e32549190c1f533dde5bcadaf83bdf23972cf0/lightgbm-4.3.0-py3-none-win_amd64.whl.metadata\n",
      "  Downloading lightgbm-4.3.0-py3-none-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy in d:\\java1\\lib\\site-packages (from lightgbm) (1.24.3)\n",
      "Requirement already satisfied: scipy in d:\\java1\\lib\\site-packages (from lightgbm) (1.10.1)\n",
      "Downloading lightgbm-4.3.0-py3-none-win_amd64.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.1/1.3 MB 939.4 kB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.1/1.3 MB 939.4 kB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.2/1.3 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.5/1.3 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.8/1.3 MB 2.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 0.9/1.3 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 0.9/1.3 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 0.9/1.3 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 2.4 MB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.3.0\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "39612c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in d:\\java1\\lib\\site-packages (1.2.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: graphviz in d:\\java1\\lib\\site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: matplotlib in d:\\java1\\lib\\site-packages (from catboost) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in d:\\java1\\lib\\site-packages (from catboost) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.24 in d:\\java1\\lib\\site-packages (from catboost) (1.5.3)\n",
      "Requirement already satisfied: scipy in d:\\java1\\lib\\site-packages (from catboost) (1.10.1)\n",
      "Requirement already satisfied: plotly in d:\\java1\\lib\\site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: six in d:\\java1\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\java1\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\java1\\lib\\site-packages (from pandas>=0.24->catboost) (2022.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\java1\\lib\\site-packages (from matplotlib->catboost) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\java1\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\java1\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\java1\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\java1\\lib\\site-packages (from matplotlib->catboost) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\java1\\lib\\site-packages (from matplotlib->catboost) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\java1\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in d:\\java1\\lib\\site-packages (from plotly->catboost) (8.2.2)\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b048fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b3cab3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"XGBoost\", XGBClassifier()),\n",
    "    (\"LightGBM\", LGBMClassifier()),\n",
    "    (\"Ridge Classifier\", RidgeClassifier()),\n",
    "    (\"MLP Neural Net\", MLPClassifier())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "54bc4926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 95.29652351738241\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 1467, number of used features: 112\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.510566 -> initscore=0.042269\n",
      "[LightGBM] [Info] Start training from score 0.042269\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM Accuracy: 95.0920245398773\n",
      "Ridge Classifier Accuracy: 92.43353783231085\n",
      "MLP Neural Net Accuracy: 90.59304703476482\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate each model\n",
    "for name, model in models:\n",
    "    nltk_model = SklearnClassifier(model)\n",
    "    nltk_model.train(training)\n",
    "    accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
    "    print(f\"{name} Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1595c8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 95.29652351738241\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 1467, number of used features: 112\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.510566 -> initscore=0.042269\n",
      "[LightGBM] [Info] Start training from score 0.042269\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM Accuracy: 95.0920245398773\n",
      "Ridge Classifier Accuracy: 92.43353783231085\n",
      "MLP Neural Net Accuracy: 91.00204498977506\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate each model\n",
    "for name, model in models:\n",
    "    nltk_model = SklearnClassifier(model)\n",
    "    nltk_model.train(training)\n",
    "    accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
    "    print(f\"{name} Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3adca779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard logging directory setup\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "with tf.summary.create_file_writer(log_dir).as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_MODEL, HP_TRAIN_SIZE],\n",
    "        metrics=[hp.Metric('accuracy', display_name='Accuracy')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "579bf7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 95.29652351738241%\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 1467, number of used features: 112\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.510566 -> initscore=0.042269\n",
      "[LightGBM] [Info] Start training from score 0.042269\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM Accuracy: 95.0920245398773%\n",
      "Ridge Classifier Accuracy: 92.43353783231085%\n",
      "MLP Neural Net Accuracy: 91.20654396728017%\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    hparams = {\n",
    "        HP_MODEL: name,\n",
    "        HP_TRAIN_SIZE: len(training) / (len(training) + len(testing)),\n",
    "    }\n",
    "\n",
    "    # Create a unique run name for TensorBoard\n",
    "    run_name = \"run-{}-{}\".format(name, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    \n",
    "    # Start logging this run\n",
    "    with tf.summary.create_file_writer(log_dir + '/' + run_name).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "\n",
    "        # Train the model\n",
    "        nltk_model = SklearnClassifier(model)\n",
    "        nltk_model.train(training)\n",
    "\n",
    "        # Evaluate the model\n",
    "        accuracy = nltk.classify.accuracy(nltk_model, testing) * 100\n",
    "\n",
    "        # Log the accuracy\n",
    "        tf.summary.scalar('accuracy', accuracy, step=1)\n",
    "        print(f\"{name} Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "514f61b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1467\n",
      "489\n"
     ]
    }
   ],
   "source": [
    "print(len(training))\n",
    "print(len(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf8955b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "63335062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming featuresets is a list of (feature_dict, label)\n",
    "test_features, test_labels = zip(*testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cef1fe84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95       233\n",
      "           1       0.97      0.94      0.95       256\n",
      "\n",
      "    accuracy                           0.95       489\n",
      "   macro avg       0.95      0.95      0.95       489\n",
      "weighted avg       0.95      0.95      0.95       489\n",
      "\n",
      "            predicted     \n",
      "                  ham spam\n",
      "actual ham        225    8\n",
      "       spam        15  241\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 718\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 1467, number of used features: 112\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.510566 -> initscore=0.042269\n",
      "[LightGBM] [Info] Start training from score 0.042269\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model: LightGBM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       233\n",
      "           1       0.96      0.95      0.95       256\n",
      "\n",
      "    accuracy                           0.95       489\n",
      "   macro avg       0.95      0.95      0.95       489\n",
      "weighted avg       0.95      0.95      0.95       489\n",
      "\n",
      "            predicted     \n",
      "                  ham spam\n",
      "actual ham        223   10\n",
      "       spam        14  242\n",
      "\n",
      "\n",
      "Model: Ridge Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92       233\n",
      "           1       0.96      0.89      0.93       256\n",
      "\n",
      "    accuracy                           0.92       489\n",
      "   macro avg       0.93      0.93      0.92       489\n",
      "weighted avg       0.93      0.92      0.92       489\n",
      "\n",
      "            predicted     \n",
      "                  ham spam\n",
      "actual ham        223   10\n",
      "       spam        27  229\n",
      "\n",
      "\n",
      "Model: MLP Neural Net\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       233\n",
      "           1       0.92      0.91      0.92       256\n",
      "\n",
      "    accuracy                           0.91       489\n",
      "   macro avg       0.91      0.91      0.91       489\n",
      "weighted avg       0.91      0.91      0.91       489\n",
      "\n",
      "            predicted     \n",
      "                  ham spam\n",
      "actual ham        214   19\n",
      "       spam        24  232\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    # Wrap the model with NLTK\n",
    "    nltk_model = SklearnClassifier(model)\n",
    "    nltk_model.train(training)\n",
    "\n",
    "    # Predict on the testing set\n",
    "    prediction = nltk_model.classify_many(test_features)\n",
    "\n",
    "    # Print the name of the model\n",
    "    print(f\"Model: {name}\")\n",
    "\n",
    "    # Print classification report\n",
    "    print(classification_report(test_labels, prediction))\n",
    "\n",
    "    # Print confusion matrix\n",
    "    confusion_mat = confusion_matrix(test_labels, prediction)\n",
    "    print(pd.DataFrame(confusion_mat, \n",
    "                       index=[['actual', 'actual'], ['ham', 'spam']], \n",
    "                       columns=[['predicted', 'predicted'], ['ham', 'spam']]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229919d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
